{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy - scientific library for Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy` is buildt on top of the `numpy` framework for multidimensional arrays, and provides a large number of higher-level scientific algorithms. Some of the topics that SciPy covers are:\n",
    "\n",
    "* Special functions ([scipy.special](http://docs.scipy.org/doc/scipy/reference/special.html))\n",
    "* Integration ([scipy.integrate](http://docs.scipy.org/doc/scipy/reference/integrate.html))\n",
    "* Optimization ([scipy.optimize](http://docs.scipy.org/doc/scipy/reference/optimize.html))\n",
    "* Interpolation ([scipy.interpolate](http://docs.scipy.org/doc/scipy/reference/interpolate.html))\n",
    "* Fourier Transforms ([scipy.fftpack](http://docs.scipy.org/doc/scipy/reference/fftpack.html))\n",
    "* Signal Processing ([scipy.signal](http://docs.scipy.org/doc/scipy/reference/signal.html))\n",
    "* Linear Algebra ([scipy.linalg](http://docs.scipy.org/doc/scipy/reference/linalg.html))\n",
    "* Sparse Eigenvalue Problems ([scipy.sparse](http://docs.scipy.org/doc/scipy/reference/sparse.html))\n",
    "* Statistics ([scipy.stats](http://docs.scipy.org/doc/scipy/reference/stats.html))\n",
    "* Multi-dimensional image processing ([scipy.ndimage](http://docs.scipy.org/doc/scipy/reference/ndimage.html))\n",
    "* File IO ([scipy.io](http://docs.scipy.org/doc/scipy/reference/io.html))\n",
    "\n",
    "Each of these submodules provides a number of functions and classes that can be used to solve problems in their respective topics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special functions\n",
    "Scipy implements a large amount of *special functions* (Bessel function,\n",
    "Airy function, orthogonal polynomials, ...) for numneric calculations. They can be used as functions within `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.special as ss\n",
    "\n",
    "# we plot the n\\in [1..3] Legendre polynomials.\n",
    "#\n",
    "x = np.linspace(-1.0, 1.0, 100)\n",
    "\n",
    "for n in range(1, 4):\n",
    "    y = ss.eval_legendre(n, x)\n",
    "    plt.plot(x, y, label=r\"$L_%d(x)$\" % n)\n",
    "    \n",
    "plt.legend()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Numerical Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Numerical evaluation of a function of the type\n",
    "\n",
    "$\\displaystyle \\int_a^b f(x) dx$\n",
    "\n",
    "is called *numerical integration*, or *quadature*.\n",
    "`Scipy` provides many funtions for quadrature, for example the `quad` and `dblquad` for single and double integrals, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the follwoing I show simple examples to demonstrate the basic usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.integrate as si\n",
    "import scipy\n",
    "\n",
    "# A normlised Gauss function\n",
    "def gauss(x):\n",
    "    factor = (1.0 / np.sqrt(2.0 * np.pi))\n",
    "    expon = np.exp(-(x)**2 / 2.0)\n",
    "    \n",
    "    return factor * expon\n",
    "\n",
    "# lower and upper integration limits:\n",
    "x_lower = 0 # the lower limit of x\n",
    "x_upper = 1 # the upper limit of x\n",
    "\n",
    "result, abserr = si.quad(gauss, x_lower, x_upper)\n",
    "\n",
    "print(\"integral value = %f; absolute error = %e\" % (result, abserr))\n",
    "\n",
    "# Also infinite limits are possible:\n",
    "result, abserr = si.quad(gauss, -scipy.Inf, scipy.Inf)\n",
    "\n",
    "print(\"integral value = %f; absolute error = %e\" % (result, abserr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simple functions we can use a lambda expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as si\n",
    "import numpy as np\n",
    "\n",
    "val, abserr = si.quad(lambda x: (np.sin(x) + np.cos(x)**2),\n",
    "                      0, np.pi / 2.)\n",
    "\n",
    "print(\"result  = %f +/- %e\" % (val, abserr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-dimensional integrals work similarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as si\n",
    "import numpy as np\n",
    "\n",
    "def integrand(x, y):\n",
    "    return np.exp(-x**2 - y**2)\n",
    "\n",
    "x_lower = 0  \n",
    "x_upper = 10\n",
    "y_lower = 0\n",
    "y_upper = 10\n",
    "\n",
    "# note that the y-limits depend on x in general;\n",
    "# hence they need to be given as functions of x!\n",
    "val, abserr = si.dblquad(integrand, x_lower, x_upper, lambda x : y_lower, lambda x: y_upper)\n",
    "\n",
    "print(val, abserr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate the two-dimensional function $f(x, y) = \\sqrt{x^2 + y^2}$ over a circle with radius $r=10$ around the origin. Perform the integration in the following two ways and compare the results:\n",
    "- In polar coordinates the problem reduces to the one-dimensional integration\n",
    "  $$I=2\\pi\\int_0^{10} r^2\\, {\\rm d}r$$\n",
    "- When implementing a two-dimensional integration it is sufficient to perform te integral in the first quadrant and to multiply the result by 4 (symmetries).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optimization / Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining a parametric model $y = m(x; a_0, a_1, \\dots a_n)$, where the $a_i$ are parameters we would like to determine) to given data points\n",
    "$(x_i; y_i \\pm \\Delta y_i);\\; i\\in [1, \\dots, m]$ is called *data-fitting*. Usually the measurements $y_i$ come with some errors $\\Delta y_i$. `Scipy` offers several functions for data fitting and I will show you the simplest one: `curve_fit`. It determines the best fit parameters with the $\\chi^2$-method, i.e. it determines best fit parameters by minimizing the expression:\n",
    "\n",
    "$$\n",
    "\\chi^2 = \\sum_{i=1}^n\\frac{(y_i-m(x_i; a_0, a_1, \\dots a_n))^2}{(\\Delta y_i)^2}\n",
    "$$\n",
    "\n",
    "Please read the [curve_fit documentation](http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit) on details (error handling etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For demonstration purposes we perform a line fit on some fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import scipy.optimize as so\n",
    "\n",
    "# create some fake data and plot them:\n",
    "x = np.random.uniform(0., 100., 100)\n",
    "# The error on each point comes from a normal distribution\n",
    "# with sigma = 10\n",
    "y = 2. * x + 2.6 + np.random.normal(0., 10., 100)\n",
    "plt.errorbar(x, y, yerr=10, fmt=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_line(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "# now perform the fit\n",
    "# Please read carefully the documentation to see how errors\n",
    "# are handled. In Physics we typically give absolute errors,\n",
    "# note relative ones!\n",
    "popt, pcov = so.curve_fit(fit_line, x, y,\n",
    "                          sigma = np.ones(len(x)) * 10,\n",
    "                          absolute_sigma=True)\n",
    "print(popt, pcov)\n",
    "print(\"a = %f +/- %f\" % (popt[0], np.sqrt(pcov[0][0])))\n",
    "print(\"b = %f +/- %f\" % (popt[1], np.sqrt(pcov[1][1])))\n",
    "\n",
    "x_fit = np.linspace(0.0, 100, 100)\n",
    "y_fit = fit_line(x_fit, *(popt))\n",
    "plt.errorbar(x, y, yerr=10, fmt=\".\")\n",
    "plt.plot(x_fit, y_fit, 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "We look at a [(fake) dataset](data/decay_data.txt) showing the rate of detection of alpha particles close to a radioactive sample, which we will call element X. The rate of detection of alpha particles is measured at 100 different times (given by the first column, in days since the start of the experiment), and for each of these times, both the rate of detection and the uncertainty in the rate of detection are given (in the second and third columns, in detections per second).\n",
    "\n",
    "- Plot the rate of detection versus time, including error bars \n",
    "\n",
    "  **Hint:** This can be done with the function `plt.errorbar`.\n",
    "- The rate of decay of a radioactive element is (theoretically) given by:\n",
    "\\begin{equation}\n",
    "  R(t) = A{\\rm e}^{-t/\\tau},\n",
    "\\end{equation}\n",
    "  where $A$ is the rate of decay at time $t=0$, and $\\tau$ is the  *mean lifetime* of the element. Perform a fit of this function to the data and overplot the resulting best-fit function over the data. $A$ and $\\tau$ are the fit parameters of your model. Is the fit good?\n",
    "- We want to consider a constant background due to possible background radiation in our model:\n",
    "\\begin{equation}\n",
    "  R_{\\rm bg}(t) = A{\\rm e}^{-t/\\tau} + B\n",
    "\\end{equation}\n",
    "  Fit this new model (three fit paramters!) to the data and overplot the new best-fit model to the data.\n",
    "-   One way to quantify the *goodness* of a fit is to consider the reduced $\\chi^2$ value of the fit, defined as:\n",
    "\\begin{equation}\n",
    "  \\chi_{\\rm red}^2 = \\frac{1}{N - p - 1}\\sum_{i=1}^{N}~    \\left(\\frac{y_i - m_i}{\\sigma_i}\\right)^2\n",
    "\\end{equation}\n",
    "  where $N$ is the number of datapoints, $p$ is the number of parameters for the model, $y_i$ are the data values, $m_i$ are the model values at the same positions, and $\\sigma_i$ are the uncertainties on the data $y_i$. A fit is considered to be good if $\\chi_{\\rm red}^2 \\approx 1$. Compute $\\chi_{\\rm red}^2$ for both models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution jere"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
